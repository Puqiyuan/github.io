#+TITLE: 进程地址空间
#+AUTHOR: Cauchy(pqy7172@gmail.com)
#+OPTIONS: ^:nil
#+EMAIL: pqy7172@gmail.com
#+HTML_HEAD: <link rel="stylesheet" href="../../../org-manual.css" type="text/css">

虚拟内存的一个主要优点是每个进程都可以有它自己的虚拟地址空间，而虚拟地址空间又由操作系统映射到物理内存．这章会讨论下进程地址空间以及Linux如何管理它．

内核对待用户地址空间和内核空间是很不同的．比如，对于内核的内存请求会立即满足，而且不论在CPU上运行的是什么进程都是全局可见的．而对于进程来说，请求的空间只是通过将页表条目指向一个只读的全局的初始化为0的页面，这样可以做到在线性地址空间里预留一部分空间．到写的时候，触发page fault，这时才会真正的分配页面，并且将这个条目放在页表里．

用户地址空间是不可信任以及不是一成不变的，在上下文切换后，用户地址空间部分有可能会改变．因此，内核必须能够捕获所有来自用户空间的异常和地址错误．

本文首先介绍线性地址是如何划分以及各个部分的目的．随后会介绍描述每个进程的结构体，这些结构体是如何被分配，初始化以及怎么销毁的．随后会介绍进程的地址空间是如何创建的以及相关联的函数．这些会引入关于进程地址空间的异常处理，pagefault等其它机制．最后会介绍下如何安全的向用户空间拷贝数据或者从用户空间拷贝数据到内核空间．

* 线性地址空间

从用户的观点来说，线性地址空间是平坦的．但是从内核空间来说就很不一样了．地址空间被划分为两部分，用户空间部分，在上下文切换后可能会改变，而内核空间，保持不变．而划分出这个位置的就是PAGE_OFFSET，对于X86来说这个值是0xC0000000．这意味着3GB留给进程，而1GB留给内核空间，内核所看到的地址空间划分如下图：
#+CAPTION: 内核看到的地址空间
#+LABEL: fig:
#+ATTR_HTML: alt="" title="" align="center" :width 50% :height 50%
[[./img/kas.png]]

* 管理地址空间
进程用到的地址空间，由mm_struct结构体管理着，它类似于BSD里的vmspace．

每个地址空间都由一些页对齐的内存组成，这些页不会重叠．进程虚拟地址空间里又分许多的region，这些region由struct vm_area_struct结构体表示，举个具体的例子，一个region(struct
vm_area_struct)可能代表由malloc分配出来的堆，针对共享库的内存映射文件，以及mmap出来的匿名内存．针对区域里的页，也许是等待分配，也许是活跃的，也许在物理内存里，也许换出了．

如果一个region映射到一个文件，那么它的vm_file就会被设置．通过vm_file(file)->f_mapping(address_space)->host(inode)就可找到对应的文件，不同结构体间的关系如下图：

#+CAPTION: 地址空间相关的结构体
#+LABEL: fig:
#+ATTR_HTML: alt="" title="" align="center" :width 30% :height 30%
[[./img/ds_as.png]]

下面列出一些和内存区域相关的syscall：

+ fork
  
  创建一个新的进程并赋予一个新的地址空间．所有的页都被标记为Copy-On-Write（COW），并且这两个进程共享这些页，直到一个page fault缺页发生时．一旦一个写错误发生，对于引起错误的进程，将会拷贝一个新的COW页．

+ clone

  clone允许一个新的进程按部分共享它的环境，以及怎样实现线程．不给clone传CLONE_VM的话，就会创建一个新的地址空间，这就和fork完全一样了．

+ mmap

  mmap在进程的线性地址空间创建一个新的区域．

+ mremap

  重新映射或者调整一段内存的大小．如果将要unmap的区域位于存在区域的中间，那么这个存在的区域将会被划分为两个独立的内存区域．

+ munmap

  销毁部分或全部的内存区域．如果要被unmap的区域位于存在内存区域的中间，那么这个存在的区域将会被划分为两个独立的内存区域．

+ shmat

  附加一个共享的内存段到进程地址空间．

+ shmdt

  从进程地址空间移除一个共享内存段．

+ execve

  加载一个新的可执行文件并且替代当前的进程地址空间．

+ exit

  销毁地址空间．
  
* 进程地址空间描述符
进程地址空间由mm_struct描述，就是说对于一个进程来说，仅有一个mm_struct，并且这个mm_struct由用户线程共享．实际上，线程的寻找方式就是，找出所有指向同一个mm_strcut的task_struct(s).

对于内核线程来说mm_struct是不需要的，因为除了vmalloc其它情况是不会page fault的．

mm_struct有两个引用计数成员，mm_user和mm_count．mm_user计数了有多少个进程访问mm_struct的用户空间部分．mm_count则是计数了对于mm_struct整个空间有多少用户在使用．当这个计数器降到0时，mm_struct就会被销毁．

mm_struct结构体成员如下：
#+begin_src c
struct mm_struct {
    struct vm_area_struct *mmap
    struct rb_root mm_rb;
    pgd_t * pgd;
    atomic_t mm_users;
    atomic_t mm_count;
    spinlock_t page_table_lock;
    struct list_head mmlist;
    unsigned long start_code, end_code, start_data, end_data;
    unsigned long start_brk, brk, start_stack;
    unsigned long arg_start, arg_end, env_start, env_end;
    unsigned long total_vm;
    unsigned long locked_vm;
    unsigned long def_flags;
    mm_context_t context;
}

#+end_src
下面解释下各个成员的意义：
+ mmap：在地址空间中所有VMA的头vma．
+ mm_rb：VMAs组织成链表或者红黑树的形式，红黑树是为了快速查询，该成员就是这颗树的根．
+ pgd：该进程的pgd．
+ mm_users：访问地址空间的用户空间部分的用户数．
+ mm_count：mm_struct的用户数．
+ page_table_lock：保护在mm_struct中的成员，包括page table等．
+ mmlist：所有的mm_structs通过这个成员连接起来．
+ start_code，end_code：代码段的开始和结束位置．
+ start_data，end_data：数据段的开始和结束位置．
+ start_brk，brk：堆的开始和结束位置．
+ start_stack：栈的开始位置．
+ arg_start，arg_end：命令行参数的开始和结尾处．
+ env_start，env_end：环境变量的开始和结束处．
+ total_vm：进程里被所有VMA占有的虚拟内存空间．
+ locked_vm：锁在内存中的常驻页面，也就是设置有PG_mlocked的页面．
+ def_flags：仅可能有一个值，VM_LOCKED，用来表征未来的映射是否都是上锁的．
+ context：架构相关的MMU上下文．

下面介绍几个函数用来处理mm_struct结构体：\\
mm_init()：设置mm_struct中成员的初始值，比如PGD，初始化锁等．\\
allocate_mm：从slab分配器中分配一个mm_struct结构体．\\
mm_alloc：通过调用allocate_mm分配mm_struct，并用mm_init来初始化．\\
exit_mmap：遍历mm_struct，解除所有的VMA映射．\\
copy_mm：仅在fork中使用，将当前的mm_struct精确的拷贝一份到新的任务中．\\
free_mm：将mm_struct返回到slab分配器．

** 分配mm_struct描述符
有两个函数可以用于分配mm_struct，它们看起来容易混淆．一是allocate_mm，它是一个预定义的宏，单纯从slab allocator里分配mm_struct．而mm_alloc除了调用allocate_mm分配一个mm_struct，还得调用mm_init初始化．

** 初始化描述符
系统里的第一个mm_struct叫做init_mm．后面的mm_struct都是父进程mm_struct的拷贝．init_mm在编译时静态的初始化好了．如下：
#+begin_src c
struct mm_struct init_mm = {
	.mm_rb		= RB_ROOT,
	.pgd		= swapper_pg_dir,
	.mm_users	= ATOMIC_INIT(2),
	.mm_count	= ATOMIC_INIT(1),
	.write_protect_seq = SEQCNT_ZERO(init_mm.write_protect_seq),
	MMAP_LOCK_INITIALIZER(init_mm)
	.page_table_lock =  __SPIN_LOCK_UNLOCKED(init_mm.page_table_lock),
	.arg_lock	=  __SPIN_LOCK_UNLOCKED(init_mm.arg_lock),
	.mmlist		= LIST_HEAD_INIT(init_mm.mmlist),
	.user_ns	= &init_user_ns,
	.cpu_bitmap	= CPU_BITS_NONE,
	INIT_MM_CONTEXT(init_mm)
};
#+end_src

而复制mm_struct的函数是copy_mm．

** 销毁mm_struct
使用atomic_inc(&mm->mm_users)可以增加用户计数，而mmput会递减这个数字．如果减到0，所有的映射就都会被exit_mmap取消．
* 内存区域（regions）
一个进程的完整地址空间是很少使用到的，仅有稀疏的几个区域会被用到，这样的每个区域被vm_area_struct结构体表示，这样的vm_area_struct不会重叠，并且一个vm_area_struct内具有相同的保护目的．举个例子，一个只读的共享库就会被加载到同一个地址空间（内存区域）．通过/proc/PID/maps可以查看一个进程映射的所有内存区域．

一个内存区域可以有许多不同的结构体，就vm_area_struct它自己可以用来表示匿名内存．

如果一个内存区域映射到文件，file类型的vm_file成员可以代表这个文件．它有类型为struct inode指针的成员，而inode又有struct address_space，这里面包括了文件的私有信息，包括许多函数指针用来执行特定于文件系统相关的一些操作，比如读写一个页到磁盘．

vm_area_struct定义如下，注意下面的成员都是摘取的一部分，其相对位置也不一定正确，只是说结构体里有这个成员：

#+begin_src c
struct vm_area_struct {
    unsigned long vm_start;
    unsigned long vm_end;
    struct mm_struct *vm_mm;
    struct vm_area_struct *vm_next, *vm_prev;
    pgprot_t vm_page_prot;
    unsigned long vm_flags;
    struct rb_node vm_rb;
    const struct vm_operations_struct *vm_ops;
    unsigned long vm_pgoff;
    struct file * vm_file;
    void * vm_private_data
}
#+end_src
下面简单解释下这些成员的意义：
+ vm_mm
  
  当前vma属于哪个mm_struct．

+ vm_start

  该区域的开始地址.

+ vm_end

  该区域的结束地址．

+ vm_next，vm_prev

  属于该task的所有vma，依地址排序．

+ vm_page_prot

  在VMA中设置PTE时，应当置上的标签．

+ vm_flags

  描述VMA保护属性，这些属性见后面的表．

  关于vm_flags可以取的值
  \\
  保护标志：
  | 标志名        | 描述                     |
  | VM_READ       | 页面可读                 |
  | VM_WRITE      | 页面可写                 |
  | VM_EXEC       | 页面可执行               |
  | VM_SHARED     | 页面是共享的             |
  | VM_DONTCOPY   | 在fork时不拷贝           |
  | VM_DONTEXPAND | 不允许该区域重新调整大小 |
  \\
  mmap相关的标志：
  | VM_MAYREAD   | 允许设置VM_READ标志        |
  | VM_MAYWRITE  | 允许设置VM_WRITE标志       |
  | VM_MAYEXEC   | 允许设置VM_EXEC标志        |
  | VM_MAYSHARE  | 允许设置VM_SHARE标志       |
  | VM_GROWSDOWN | 共享段（可能是栈）可以减小 |
  | VM_GROWSUP   | 共享段（可能是堆）可以增长 |
  \\
  锁相关的标志：
  | VM_LOCKED | 如果设置了，页面就不会被换出，可以由mlock设置 |
  | VM_IO     | 映射的区域用于I/O设备                         |

+ vm_rb

  以链表的形式组织，为了可以快速查询，所有的VMA都存在于一个红黑树中．在处理page fault时，为了快速找到正确的VMA，这种组织方式是很重要的，尤其是有许多区域（region）时．

+ vm_ops

  主要是一些函数指针用于处理该VMA，包括open，close，以及缺页时的入口fault函数．

+ long vm_pgoff

  页面对齐的偏移．

+ vm_file

  映射到哪个文件（可以为空）．

+ vm_private_data

  由某些设备驱动使用存储一些私有信息，内存管理器不关心．

所有的区域都可以通过vm_next和vm_prev链接起来，由于page-fault的频繁性，以红黑树组织起来，搜索时间就只有O(logN)了．地址较低的节点在左边，较高的在右边．

** 内存区域操作
一个VMA可以支持三个操作，比如open，close以及fault．VMA可以通过vm_operations_struct来实现这
三个操作．这三个函数指针的定义如下：
#+begin_src c
struct vm_operations_struct {
	void (*open)(struct vm_area_struct * area);
	void (*close)(struct vm_area_struct * area);
    vm_fault_t (*fault)(struct vm_fault *vmf);
}
#+end_src
当一个区域创建时就会调用open，而删除时调用close．而fault函数是do_page_fault流程里会用到的函数．

许多文件映射的都会使用一个vm_operations_struct类型的通用结构体generic_file_vm_ops．里面会注册fault函数：
#+begin_src c
.fault          = filemap_fault
#+end_src
** 映射文件/设备
当一个区域由文件映射时，其vm_file成员都会包含一个address_space类型的f_mapping成员．
address_space通常包含以下几个成员：
#+begin_src c
struct address_space {
	struct inode		*host;
    unsigned long		nrpages;
    const struct address_space_operations *a_ops;
}
#+end_src

简单介绍下这几个成员：
+ host

  文件对应的inode．

+ nrpages

  由该地址空间使用的，在内存里的页面数量．

+ a_ops

  函数指针的集合，用来操作文件系统．每个文件系统都会提供它自己的address_space_operations，当然有时也使用通用的函数

内存管理器会周期性的刷新信息到磁盘．内存管理器不需要知道也不关心信息是怎样被写入到磁盘的，
a_ops里的函数用来完成相关的事情：

#+begin_src c
struct address_space_operations {
	int (*writepage)(struct page *page, struct writeback_control *wbc);
    int (*readpage)(struct file *, struct page *);
    sector_t (*bmap)(struct address_space *, sector_t);
    ssize_t (*direct_IO)(struct kiocb *, struct iov_iter *iter);
}
#+end_src

** 创建内存区域
** 查找内存区域
** 查询空闲区域
** 插入内存区域
** 合并连续区域
** 重映射区域
** 区域锁
** 解锁区域
** Fix up
** 删除一个区域
** 删除所有区域
* 异常处理
* Page Fault

* 拷贝到/拷贝自用户空间
